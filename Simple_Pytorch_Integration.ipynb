{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfrk68aIXmf8A/GqAIte7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "011163fd580c407f8db779ab17ee6642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021e2d853f1b49438009872eb3648582",
              "IPY_MODEL_ba7d2baeea75468f839242e15450d79e"
            ],
            "layout": "IPY_MODEL_c3cc15c8d653484e84862ecbb416ff4e"
          }
        },
        "021e2d853f1b49438009872eb3648582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a34a27974ca945cd8a906d44869d82af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4135521954ee4525a5602d7c81097093",
            "value": "0.010 MB of 0.010 MB uploaded\r"
          }
        },
        "ba7d2baeea75468f839242e15450d79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb00c5a845f4f2a8f1fee2f08391980",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_831a1e5f90274ce7ba23e8639f273331",
            "value": 1
          }
        },
        "c3cc15c8d653484e84862ecbb416ff4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34a27974ca945cd8a906d44869d82af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4135521954ee4525a5602d7c81097093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb00c5a845f4f2a8f1fee2f08391980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831a1e5f90274ce7ba23e8639f273331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KajetanFrackowiak/WeightBiasesLearn/blob/main/Simple_Pytorch_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W&B + PyTorch = ðŸ”¥"
      ],
      "metadata": {
        "id": "F6ur07hXG3Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb onnx -Uq"
      ],
      "metadata": {
        "id": "2otjhqFRqMFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B2IZDWlNGXWj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# remove slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "Nv4lyC74Ifwf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "d_HqD1JgWOUP",
        "outputId": "8e088204-cbfc-4345-a6e4-4a2ba0349440"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the Experiment and Pipeline"
      ],
      "metadata": {
        "id": "-3pTvikxX6a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=5,\n",
        "    classes=10,\n",
        "    kernels=[16, 32],\n",
        "    batch_size=128,\n",
        "    learning_rate=0.005,\n",
        "    dataset='MNIST',\n",
        "    architecture=\"CNN\"\n",
        ")"
      ],
      "metadata": {
        "id": "qi_Dte-jWUky"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "\n",
        "  # Tell wandb to get started\n",
        "  with wandb.init(project=\"pytorch-demo\", config=hyperparameters):\n",
        "    # access all HPs through wandb.config, so loggin matches execution!\n",
        "    config = wandb.config\n",
        "\n",
        "    # make the model, data, and optimization problem\n",
        "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "\n",
        "    # and use them to train the model\n",
        "    train(model, train_loader, criterion, optimizer, config)\n",
        "\n",
        "    # and test its final performance\n",
        "    test(model, test_loader)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ObWBX9rTYRnl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "  # Make the data\n",
        "  train, test = get_data(train=True), get_data(train=False)\n",
        "  train_loader = make_loader(train, batchsize=config.batch_size)\n",
        "  test_loader = make_loader(test, batchsize=config.batch_size)\n",
        "\n",
        "  # Make the model\n",
        "  model = ConvNet(config.kernels, config.classes).to(device)\n",
        "\n",
        "  # Make the loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(\n",
        "      model.parameter(), lr=config.learning_rate)\n",
        "\n",
        "  return model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "d9He8cmcZq5R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conventional and convolutional neural network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, kernels, classes=10):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(x)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "_WvH0ucCcvgC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Training logic"
      ],
      "metadata": {
        "id": "kesADDTJfqjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, criterion, optimizer, config):\n",
        "  # Tell wandb to watch what the model gets up to: gradients, weight and model\n",
        "  wandb.watch(model, criterion, log=\"all\", log_frq=10)\n",
        "\n",
        "  # Run training and track with wandb\n",
        "  total_batches = len(loader) * config.epochs\n",
        "  example_ct = 0  # Number of examples seen\n",
        "  batch_ct = 0\n",
        "  for epoch in tqdm(range(config.epochs)):\n",
        "    for _, (images, labels) in enumerate(loader):\n",
        "\n",
        "      loss = train_batch(images, labels, model, optimizer, criterion)\n",
        "      example_ct += len(images)\n",
        "      batch_ct += 1\n",
        "\n",
        "      # Report metrics every 25th batch\n",
        "      if ((batch_ct + 1) % 25) == 0:\n",
        "        train_log(loss, example_ct, epoch)\n",
        "\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "  images, lables = images.to(device), labels.to(device)\n",
        "\n",
        "  # Forward pass ->\n",
        "  outputs = model(images)\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Backward pass ->\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  # Step with optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "J2iHUICAfZ16"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "  loss = float(loss)\n",
        "\n",
        "  # where the magic happens\n",
        "  wandb.loss({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "  print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "ytI0g1GeibvN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define Testing Logic"
      ],
      "metadata": {
        "id": "M5l3vG19jSf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  # Run the model on some test examples\n",
        "  with torch.no_grad():\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs =  model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy of the model on the {total}\" +\n",
        "          f\"test images: {100 * correct / total}%\")\n",
        "\n",
        "    wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "  # Save the model in the exchangeable ONNX format\n",
        "  torch.onnx.export(model, images, \"model.onnx\")\n",
        "  wandb.save(\"model.onnx\")"
      ],
      "metadata": {
        "id": "jxXIWBdPi6Nk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build, train and analyze the model with the pipeline\n",
        "model = model_pipeline(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599,
          "referenced_widgets": [
            "011163fd580c407f8db779ab17ee6642",
            "021e2d853f1b49438009872eb3648582",
            "ba7d2baeea75468f839242e15450d79e",
            "c3cc15c8d653484e84862ecbb416ff4e",
            "a34a27974ca945cd8a906d44869d82af",
            "4135521954ee4525a5602d7c81097093",
            "4bb00c5a845f4f2a8f1fee2f08391980",
            "831a1e5f90274ce7ba23e8639f273331"
          ]
        },
        "id": "yk9xf6ZbkzLL",
        "outputId": "8ffd75ae-c9fe-4e98-bb6e-672adf4b5f89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrackowiak\u001b[0m (\u001b[33mfrackowiak_kajetan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231111_182729-9mcnrch4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/frackowiak_kajetan/pytorch-demo/runs/9mcnrch4' target=\"_blank\">dutiful-capybara-1</a></strong> to <a href='https://wandb.ai/frackowiak_kajetan/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/frackowiak_kajetan/pytorch-demo' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/pytorch-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/frackowiak_kajetan/pytorch-demo/runs/9mcnrch4' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/pytorch-demo/runs/9mcnrch4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-9-338f5da09198>\", line 9, in model_pipeline\n",
            "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
            "  File \"<ipython-input-10-a5f8c301fdba>\", line 3, in make\n",
            "    train, test = get_data(train=True), get_data(train=False)\n",
            "NameError: name 'get_data' is not defined\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "011163fd580c407f8db779ab17ee6642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dutiful-capybara-1</strong> at: <a href='https://wandb.ai/frackowiak_kajetan/pytorch-demo/runs/9mcnrch4' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/pytorch-demo/runs/9mcnrch4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231111_182729-9mcnrch4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-78fbf03a599a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build, train and analyze the model with the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-338f5da09198>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# make the model, data, and optimization problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# and use them to train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a5f8c301fdba>\u001b[0m in \u001b[0;36mmake\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Make the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Za_EDZrTo42u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}